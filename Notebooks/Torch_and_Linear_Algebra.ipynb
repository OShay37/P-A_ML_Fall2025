{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1d3c2c",
   "metadata": {},
   "source": [
    "# Introduction to _PyTorch_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b570e",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "_*PyTorch*_ is an open-source deep learning framework developed by Facebook's AI Research lab. It provides a flexible and efficient platform for building and training neural networks, supporting dynamic computation graphs and GPU acceleration. PyTorch is widely used in both academia and industry for research and production due to its intuitive interface and strong community support.\n",
    "\n",
    "For more details, visit the [official PyTorch documentation](https://pytorch.org/docs/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4390e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299d1272",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb782d0",
   "metadata": {},
   "source": [
    "In machine learning we will deal with tensors a lot. As a reminder 1-d tensor is a vector (called array in programming jargon); a 2-d tensor is a matrix; if dimentions are k>2 we talk about $k^{th}$-order tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b3c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(12, dtype=torch.float32)\n",
    "print('printing the x vector:', x) \n",
    "# note that in jupyter notebooks, the output of the last line is automatically displayed even without a print statement:\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c20730",
   "metadata": {},
   "source": [
    "### Counting elements, shape and reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c36fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf8a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb650be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reshape(3, 4) # Reshape to 3 rows and 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3368c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape) #note that this does not change the original tensor! you need to assign it to a new variable or overwrite the original one\n",
    "X = x.reshape(3, 4) # Now x is reshaped\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a93f25",
   "metadata": {},
   "source": [
    "### zeros-, ones- and rand-tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecf51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros((2, 3, 4)) # this creates a 3-d tensor of shape (2, 3, 4) filled with zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones((2, 3, 4)) # this creates a 3-d tensor of shape (2, 3, 4) filled with ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a41c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(3, 4) # this creates a 2-d tensor of shape (3, 4) filled with random numbers from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[2, 1, 4, 3], \n",
    "              [1, 2, 3, 4], \n",
    "              [4, 3, 2, 1]]).shape # Create a 2D tensor with specific values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0421b615",
   "metadata": {},
   "source": [
    "### Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1c19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X #we defined X above, so this will show the reshaped tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0] # Access the first row of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[-1] # Access the last row of the tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4174e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[1:3] # Access rows 1 and 2 of the tensor. Note that index 3 is not included!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9232967",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[1, 2] = 17 # Change the value at row 1, column 2 to 17\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f791d706",
   "metadata": {},
   "source": [
    "-------------------- *YOUR TURN*!!! ----------------\n",
    "\n",
    "Now try to overwrite all values in the forst 2 rows of the vector to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e3bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrtite your own code to overwrite all values in the first 2 rows of the vector to 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa7ab71",
   "metadata": {},
   "source": [
    "### Operation between tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c755c89",
   "metadata": {},
   "source": [
    "Element-wise operations \n",
    "1) thourgh unitary scalar operations \n",
    "2) through binary scalar operations \n",
    "3) through broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106c3102",
   "metadata": {},
   "source": [
    "-------------------- *YOUR TURN*!!! ----------------\n",
    "\n",
    "Generate 2 arrays, x and y, on length 5 (aka 5 number of elements each); then try the following operations:\n",
    "x + y, x - y, x * y, x / y, x ** y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e2aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your own code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b220f1d1",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bedcd0",
   "metadata": {},
   "source": [
    "Under certain conditions, even when shapes differ, we can still perform ele- mentwise binary operations by invoking the broadcasting mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0fe989",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e9b0aa",
   "metadata": {},
   "source": [
    "Since a and b are 3 × 1 and 1 × 2 matrices, respectively, their shapes do not match up. Broadcasting produces a larger 3 × 2 matrix by replicating matrix a along the columns and matrix b along the rows before adding them elementwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186ae70e",
   "metadata": {},
   "source": [
    "### Concatenate tensors, logical statements and sum-all-elements operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92959b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be very useful when we will build Convolutional Neural Networks (CNNs) later in the course\n",
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "\n",
    "X, Y, torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35b6e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X == Y # Element-wise comparison between tensors -- returns a tensor of boolean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6746f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.sum(), X.sum(dim=0), X.sum(dim=1) # Sum all elements, sum along rows, sum along columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e246e",
   "metadata": {},
   "source": [
    "### Saving Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6780316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is crucial in machine learning, as models can have millions of parameters, and we need to save memory!\n",
    "before = id(Y) \n",
    "Y=Y+X\n",
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9dfd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = torch.zeros_like(Y)\n",
    "print('id(Z):', id(Z))\n",
    "Z[:] = X + Y\n",
    "print('id(Z):', id(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a79074a",
   "metadata": {},
   "source": [
    "### Conversion to Other Python Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba3050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how you convert a tensor to a numpy array and back \n",
    "A = X.numpy()\n",
    "B = torch.from_numpy(A)\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf4bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how you convert a tensor to a Python list (less used, but still useful)\n",
    "X.tolist(), X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b72f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7b75d4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9afb1db3",
   "metadata": {},
   "source": [
    "## Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb055ea2",
   "metadata": {},
   "source": [
    "### Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91496402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "x + y, x * y, x / y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d72ef",
   "metadata": {},
   "source": [
    "### vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b99bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), tensor(0), tensor(1), tensor(2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that python has a zero-based indexing, so the first element is at index 0\n",
    "x = torch.arange(3)\n",
    "x, x[0], x[1], x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "136fe762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x) # Count the number of elements in the tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0edaef07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # Get the shape of the tensor. Note this is a different type the the output of `len(x)`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9409342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a21d099a",
   "metadata": {},
   "source": [
    "### Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffcddd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape(3, 2)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e228ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4],\n",
       "        [1, 3, 5]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T # Transpose the matrix A. Symmetric matrices are the subset of square matrices that are equal to their own transposes\n",
    "A "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6551e81d",
   "metadata": {},
   "source": [
    "### Tensors and tensor aritmethic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1392125b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(24).reshape(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a34227e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[ 0.,  2.,  4.],\n",
       "         [ 6.,  8., 10.]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = A.clone()  # Assign a copy of A to B by allocating new memory\n",
    "A, A + B # Element-wise addition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f114b",
   "metadata": {},
   "source": [
    "### Element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aebccc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  4.],\n",
       "        [ 9., 16., 25.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B # Element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd27dcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " tensor([[[ 0,  2,  4,  6],\n",
       "          [ 8, 10, 12, 14],\n",
       "          [16, 18, 20, 22]],\n",
       " \n",
       "         [[24, 26, 28, 30],\n",
       "          [32, 34, 36, 38],\n",
       "          [40, 42, 44, 46]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4) \n",
    "a + X, a * X, (a * X).shape # addition and multiplication with a scalar, and the shape of the resulting tensor (unchanged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529b89f",
   "metadata": {},
   "source": [
    "### Sums of elements in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eaafc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(15.), tensor([3., 5., 7.]), tensor([ 3., 12.]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of elements in a tensor\n",
    "A.sum(), A.sum(dim=0), A.sum(dim=1) # Sum all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c900610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0, 1]) == A.sum() # Same as A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac0833f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.5000), tensor(2.5000))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), A.sum() / A.numel() # Mean and average of elements in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89c6b06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.5000, 2.5000, 3.5000]), tensor([1.5000, 2.5000, 3.5000]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0] # Mean and average of elements in a tensor along the first axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b005c6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " torch.Size([2, 3]),\n",
       " tensor([3., 5., 7.]),\n",
       " torch.Size([3]),\n",
       " tensor([[ 3.],\n",
       "         [12.]]),\n",
       " torch.Size([2, 1]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sometimes it can be useful to keep the number of axes unchanged when invoking the func- tion for calculating the sum or mean. \n",
    "# This matters when we want to use the broadcast mechanism.\n",
    "\n",
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "A, A.shape, A.sum(axis=0), A.sum(axis=0).shape, sum_A, sum_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d12f2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3333, 0.6667],\n",
       "        [0.2500, 0.3333, 0.4167]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since sum_A keeps its two axes after summing each row, \n",
    "# we can divide A by sum_A with broadcasting to create a matrix where each row sums up to 1.\n",
    "# this is a common technique for normalizing data, expecially for classification tasks, in which\n",
    "# we want to ensure that the sum of probabilities across each row is 1.\n",
    "A / sum_A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08122f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 5., 7.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to calculate the cumulative sum of elements of A along some axis, say axis=0, \n",
    "# we can call the cumsum function.\n",
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff4a7f",
   "metadata": {},
   "source": [
    "### Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cba9532d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product of two vectors\n",
    "x = torch.arange(3, dtype = torch.float32)\n",
    "y = torch.ones(3, dtype = torch.float32)\n",
    "x, y, torch.dot(x, y)\n",
    "# or equivalently\n",
    "torch.sum(x * y) # Element-wise multiplication followed by summation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a5092",
   "metadata": {},
   "source": [
    "### Matrix-vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50616410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]),\n",
       " torch.Size([3]),\n",
       " tensor([ 5., 14.]),\n",
       " tensor([ 5., 14.]),\n",
       " torch.Size([2]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix-vector multiplication -- this is a common operation in machine learning, especially in linear layers\n",
    "A.shape, x.shape, torch.mv(A, x), A@x, (A@x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69531c9",
   "metadata": {},
   "source": [
    "### Matrix-matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e1168ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix-matrix multiplication\n",
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = torch.ones(3, 4)\n",
    "A, B, torch.mm(A, B), A@B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907b8794",
   "metadata": {},
   "source": [
    "### Norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5d5f53",
   "metadata": {},
   "source": [
    "### l2 norm (Euclidean norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f11c3382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05ece5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(u * u).sum().sqrt()  #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac97e0",
   "metadata": {},
   "source": [
    "### l1 norm (Manhattan distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9214a049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1ff0b",
   "metadata": {},
   "source": [
    "### Frobenius norm (l2 norm for matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "019166c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1.]]),\n",
       " tensor(6.))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = torch.ones((4, 9))\n",
    "D, torch.norm(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8beb08d",
   "metadata": {},
   "source": [
    "-------------------- *YOUR TURN*!!! ----------------\n",
    "\n",
    "Define a vector x of values ranging between -5 and 5. Plot the x^2 and |x|. \n",
    "\n",
    "Looking at the plot, think about what is the effect of l2 and l1 norms of different vectors, how do their norms compare if both are computed as l2 or as l1?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "733ec168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write you code here. Fro plotttin you can use the pythin library matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ...code for plotting..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a065f88f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
